{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecab8580",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center;\">Scraping facebook group posts with <i><u>facebook_scraper</u></i> library</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86cd8e6",
   "metadata": {},
   "source": [
    "* Abdessamade OUOMAR \n"
    "* Abdelilah AITROUGA\n",
    "* Jamal BAYACINE\n"
    "* Otmane BASTOS",
    
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f156a96",
   "metadata": {},
   "source": [
    "Data scraping, also known as web scraping, is the process of automatically extracting data from websites or other sources. This data can be used for a variety of purposes, such as **research**, **analysis**, and **machine learning**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb1d855",
   "metadata": {},
   "source": [
    "There are a number of tools and techniques used for data scraping, including web scraping libraries and frameworks, such as Beautiful Soup and Scrapy. In this work we're going to use **facebook_scraper** to extract data from facebook groups and use it for social network analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfb740c",
   "metadata": {},
   "source": [
    "**facebook_scraper** is a tool that allow developers to easily extract and manipulate data from Facebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c78440",
   "metadata": {},
   "source": [
    "However, it is important to keep in mind that data scraping can potentially **violate Facebook terms of service**, and it is essential to be mindful of ethical considerations when scraping data from it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c067d75b",
   "metadata": {},
   "source": [
    "Facebook scraper link :\n",
    "https://pypi.org/project/facebook-scraper/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a4f8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from facebook_scraper import *\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07eb9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee76d9fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# If the group is private, enter your email and password\n",
    "\n",
    "em = \"e_mail@email.com\"\n",
    "pw = \"password\"\n",
    "use_persistent_session(email=em,password=pw, cookies_file_path=\"cookies.pckl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59ce543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ids or URLs of the groups that you want to scrape\n",
    "\n",
    "url = [\"ID1\",\"ID2\",..]\n",
    "groups = []\n",
    "\n",
    "# Lets get some informations about the groups\n",
    "\n",
    "for u in url:\n",
    "    group = get_group_info(group = u)\n",
    "    groups.append(group)\n",
    "groups_info = pd.DataFrame(groups)\n",
    "groups_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ce1d16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now lets get the posts of each group, this may take several minutes\n",
    "\n",
    "posts1 = get_posts(group = groups_info['id'][0], pages=100, options={\"comments\":True,\"progress\": True,\"reactors\": True})\n",
    "posts2 = get_posts(group = groups_info['id'][1], pages=100, options={\"comments\":True,\"progress\": True,\"reactors\": True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd0acaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract posts\n",
    "\n",
    "all_posts_grp1 = []\n",
    "all_posts_grp2 = []\n",
    "for pst1,pst2 in zip(posts1,posts2):\n",
    "    all_posts_grp1.append(pst1)\n",
    "    all_posts_grp2.append(pst2)\n",
    "print(\"Nombre de posts trouver pour le group {} est : {}\".format(\"ID1\", len(all_posts_grp1)))\n",
    "print(\"Nombre de posts trouver pour le group {} est : {}\".format(\"ID2\", len(all_posts_grp2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a8b73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_posts1 = pd.DataFrame(all_posts_grp1)\n",
    "data_posts2 = pd.DataFrame(all_posts_grp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22d3587",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_posts1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113eb20f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_posts2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5d6ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many null values we've got from scraping posts\n",
    "\n",
    "print(\"--- Group ID : {} ---\\n\".format(groups_info['id'][0]))\n",
    "print(data_posts1.isna().sum())\n",
    "print(\"\\n--- Group ID : {} ---\\n\".format(groups_info['id'][1]))\n",
    "print(data_posts2.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b172a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to get information about users\n",
    "\n",
    "profils = []\n",
    "for i in data_posts['user_id']:\n",
    "    profils.append(get_profile(str(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da60d9af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_profiles = pd.DataFrame(profils)\n",
    "data_profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5f0afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to get friends of a USER, it works only if the friends list is public\n",
    "\n",
    "frnds = get_friends(\"USER_ID\")\n",
    "list(frnds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ec2738",
   "metadata": {},
   "source": [
    "### Saving data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a1395f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path  \n",
    "filepath1 = Path('group1.csv')\n",
    "filepath2 = Path('group2.csv')\n",
    "filepath1.parent.mkdir(parents=True, exist_ok=True)\n",
    "filepath2.parent.mkdir(parents=True, exist_ok=True) \n",
    "data_posts1.to_csv(filepath1)\n",
    "data_posts2.to_csv(filepath2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
